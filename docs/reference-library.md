# Reference Library

This curated collection provides resources to help you get started working with AI agents and is organized into four main sections:

- [Academic Papers](#academic-papers) - Current research across specialized domains.
- [Industry Insights](#industry-insights) - Real-world applications and case studies.
- [Agent Repositories](#agent-repositories) - Open-source implementations and examples.
- [Frameworks and Solutions](#frameworks-and-solutions) - Production-ready tools and platforms.

## Academic Papers

Recent research papers exploring various aspects of AI agents, organized by key focus areas.

### Video Agents

Publications focusing on AI agents specifically designed for video understanding and editing:

- [LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing](https://arxiv.org/abs/2402.10294)
- [VideoAgent: Long-form Video Understanding with Large Language Model as Agent](https://arxiv.org/abs/2403.10517)
- [VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding](https://arxiv.org/abs/2403.11481)
- [OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer](https://arxiv.org/abs/2406.16620)

### Agent Platforms and Frameworks

Research on architectures and platforms for building and deploying AI agents:

- [Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence](https://arxiv.org/abs/2407.07061)
- [Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://arxiv.org/abs/2401.16158)
- [Agent Workflow Memory](https://arxiv.org/abs/2409.07429)
- [OpenHands: An Open Platform for AI Software Developers as Generalist Agents](https://arxiv.org/abs/2407.16741)
- [MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents](http://arxiv.org/abs/2410.03450)
- [AgentGym: Evolving Large Language Model-based Agents across Diverse Environments](https://arxiv.org/abs/2406.04151)

### Agent Evaluation and Benchmarks

Papers focused on measuring and comparing agent performance:

- [CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark](https://arxiv.org/abs/2409.11363)
- [SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories](https://arxiv.org/abs/2409.07440)
- [Ï„-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains](https://arxiv.org/abs/2406.12045)
- [GTA: A Benchmark for General Tool Agents](http://arxiv.org/abs/2407.08713)

### Agent Surveys

Comprehensive reviews and analyses:

- [AI Agents That Matter](https://arxiv.org/abs/2407.01502)
- [LLM Multi-Agent Systems: Challenges and Open Problems](https://arxiv.org/abs/2402.03578)
- [A Survey on the Memory Mechanism of Large Language Model based Agents](https://arxiv.org/abs/2404.13501)

### Human-in-the-loop

Research on human-agent interaction and collaboration:

- [Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs](https://arxiv.org/abs/2312.14345)
- [Building Machines that Learn and Think with People](https://arxiv.org/abs/2408.03943)
- [Learning with Language-Guided State Abstractions](https://arxiv.org/abs/2402.18759)

## Industry Insights

Case studies, analysis, and trends

- [LangChain: Breakout Agentic Apps](https://www.langchain.com/breakoutagents)
  - [Ramp](https://www.langchain.com/breakoutagents/ramp)
  - [Superhuman](https://www.langchain.com/breakoutagents/superhuman)
  - [Perplexity](https://www.langchain.com/breakoutagents/perplexity)
  - [Replit](https://www.langchain.com/breakoutagents/replit)
- [LangChain: In the Loop](https://blog.langchain.dev/tag/in-the-loop/)
- [Felicis: The agentic web](https://www.felicis.com/insight/the-agentic-web)
- [Madrona: The Rise of AI Agent Infrastructure](https://www.madrona.com/the-rise-of-ai-agent-infrastructure/)

## Agent Repositories

Open-source implementations and examples:

- [GenAI Agents](https://github.com/NirDiamant/GenAI_Agents)

## Frameworks and Solutions

Production-ready tools and development frameworks:

- [Databicks: What is Mosaic AI Agent Evaluation?](https://docs.databricks.com/en/generative-ai/agent-evaluation/index.html)
- [LlamaIndex: Workflows](https://docs.llamaindex.ai/en/latest/module_guides/workflow/)
- [OpenAI: Swarm](https://github.com/openai/swarm)
- [LangGraph](https://github.com/langchain-ai/langgraph)