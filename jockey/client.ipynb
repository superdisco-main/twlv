{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph_sdk.schema import Assistant\n",
    "from rich.jupyter import print\n",
    "\n",
    "client = get_client()\n",
    "\n",
    "# List all assistants\n",
    "assistants = await client.assistants.search()\n",
    "\n",
    "# We auto-create an assistant for each graph you register in config.\n",
    "jockey: Assistant = assistants[0]\n",
    "\n",
    "# Start a new thread\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Start a streaming run\n",
    "user_input = [HumanMessage(content=\"Hello who are you?\", name=\"user\")]\n",
    "jockey_input = {\n",
    "    \"chat_history\": user_input,\n",
    "    \"made_plan\": False,\n",
    "    \"next_worker\": None,\n",
    "    \"active_plan\": None\n",
    "}\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], jockey[\"assistant_id\"], input=jockey_input, stream_mode=\"values\"):\n",
    "    print(event)\n",
    "    # if event.event == \"values\":\n",
    "    #     if event.data[\"chat_history\"][-1][\"name\"] != \"user\":\n",
    "    #         print(event.data[\"chat_history\"][-1][\"name\"], \":\", event.data[\"chat_history\"][-1][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
